# DBT com Big Query

## Ricardo Marques

## üîß Configura√ß√£o do dbt com BigQuery

Este projeto utiliza o **dbt** com o **Google BigQuery** como data warehouse.

### üìå Conex√£o via Conta de Servi√ßo com Vari√°veis de Ambiente

A conex√£o com o BigQuery foi configurada utilizando uma **conta de servi√ßo**, com os dados sens√≠veis e de configura√ß√£o extra√≠dos por meio de **vari√°veis de ambiente**, garantindo maior seguran√ßa e flexibilidade.

O arquivo `profiles.yml` utiliza as vari√°veis da seguinte forma:

```yaml
datawarehouse:
  outputs:
    dev:
      type: bigquery
      method: "{{ env_var('DBT_METHOD') }}"
      project: "{{ env_var('DBT_PROJECT') }}"
      dataset: "{{ env_var('DBT_DATASET') }}"
      keyfile: "{{ env_var('DBT_KEYFILE') }}"
      threads: "{{ env_var('DBT_THREADS') | int }}"
      job_execution_timeout_seconds: "{{ env_var('DBT_JOB_TIMEOUT') | int }}"
      location: "{{ env_var('DBT_LOCATION') }}"
      priority: "{{ env_var('DBT_PRIORITY') }}"
      job_retries: "{{ env_var('DBT_JOB_RETRIES') | int }}"
  target: dev
```

üìå Definindo as Vari√°veis de Ambiente
Essas vari√°veis devem ser definidas em um arquivo .env ou exportadas no ambiente de execu√ß√£o, por exemplo:

```bash

export DBT_METHOD=service-account
export DBT_PROJECT=seu-projeto
export DBT_DATASET=seu_dataset
export DBT_KEYFILE=/caminho/para/sua-chave.json
export DBT_THREADS=1
export DBT_JOB_TIMEOUT=300
export DBT_LOCATION=US
export DBT_PRIORITY=interactive
export DBT_JOB_RETRIES=1
```
üìÅ Uso de Profile Customizado
O dbt foi configurado para utilizar um profiles.yml fora do diret√≥rio padr√£o, sendo o caminho especificado com a flag --profiles-dir:

```bash

dbt run --profiles-dir ../

```
## üîß Uso do dbt Seed para Criar Tabelas no BigQuery

No projeto, foi utilizado o comando **`dbt seed`** para criar tabelas no **BigQuery** a partir de arquivos CSV armazenados localmente. O **dbt seed** permite carregar dados diretamente para o BigQuery e √© √∫til para importar dados de refer√™ncia ou dados est√°ticos necess√°rios para os modelos.


<p align="center">
  <img src="pic/dbt-seed.png" alt="Fluxo do dbt seed para BigQuery" width="500">
</p>


### üìå Configura√ß√£o do dbt Seed

1. **Arquivos CSV**: Os arquivos CSV com os dados a serem carregados foram armazenados na pasta `seeds/` do projeto. Esses arquivos devem estar formatados corretamente para que o dbt consiga carreg√°-los no BigQuery.

2. **Comando dbt seed**: O comando `dbt seed` foi utilizado para carregar os arquivos para o BigQuery. O dbt automaticamente cria as tabelas e carrega os dados a partir dos arquivos CSV.

   O comando utilizado foi:

   ```bash
   dbt seed

   ```

3. **Estrutura das Tabelas:** Durante a execu√ß√£o do dbt seed, o dbt cria tabelas no BigQuery com o mesmo nome dos arquivos CSV, mas na schema e projeto configurados no profiles.yml.

4. **Configura√ß√£o Adicional:** Caso haja necessidade de ajustes como a defini√ß√£o de tipos de dados ou configura√ß√µes espec√≠ficas de parti√ß√£o e clustering no BigQuery, esses par√¢metros podem ser configurados diretamente no arquivo dbt_project.yml ou dentro do pr√≥prio arquivo profiles.yml.



### üèóÔ∏è Estrutura do Projeto dbt

O projeto foi estruturado seguindo as melhores pr√°ticas de modelagem com **dbt**, utilizando os diret√≥rios:

- **`staging/`**: onde s√£o feitas as primeiras transforma√ß√µes e limpezas dos dados brutos vindos do BigQuery.
- **`intermediate/`**: camada intermedi√°ria onde os dados s√£o integrados, enriquecidos e organizados para an√°lises mais complexas.
- **`marts/`**: camada final orientada ao neg√≥cio, com tabelas e m√©tricas preparadas para consumo anal√≠tico por ferramentas de BI ou dashboards.

Essa estrutura permite organizar as transforma√ß√µes de forma clara e escal√°vel, separando responsabilidades e facilitando a manuten√ß√£o.
A modelagem conduz os dados at√© o **mart anal√≠tico**, ponto final de entrega para **an√°lises de neg√≥cio**.



## Uso do SQLFluff no Projeto DBT

Este projeto utiliza o **SQLFluff** para garantir a **qualidade e padroniza√ß√£o** do c√≥digo SQL dentro dos modelos do DBT.

### O que √© o SQLFluff?

O **SQLFluff** √© um **linter e formatter de SQL** que ajuda a manter o c√≥digo organizado e consistente. Ele verifica o c√≥digo SQL em busca de erros de sintaxe e problemas de estilo, aplicando as melhores pr√°ticas e garantindo que o c√≥digo esteja formatado corretamente.

### Objetivo do SQLFluff no Projeto

- **Garantir consist√™ncia** no estilo de c√≥digo SQL entre os modelos DBT.
- **Identificar e corrigir problemas de sintaxe**, como nomes de tabelas e colunas mal formatados.
- **Melhorar a legibilidade** do c√≥digo SQL, aplicando padr√µes de indenta√ß√£o e outras boas pr√°ticas.
- **Integrar com o DBT** para analisar os arquivos `.sql` que utilizam Jinja, como `{{ ref() }}` e `{{ source() }}`, garantindo que o linter saiba interpretar corretamente os templates do DBT.

### Como o SQLFluff √© utilizado

- O SQLFluff √© configurado com o **templater `dbt`**, que permite que ele entenda a sintaxe do DBT, incluindo `{{ ref() }}`, `{{ source() }}` e outras macros.
- O linter verifica todos os modelos SQL dentro da pasta `models/` e aplica as regras de estilo configuradas.
- **Corre√ß√µes autom√°ticas** podem ser aplicadas com o comando `sqlfluff fix`, garantindo que o c√≥digo esteja formatado corretamente antes de ser versionado.

### Como rodar o SQLFluff

Para rodar o SQLFluff no seu projeto DBT, use o seguinte comando:

```bash
poetry run sqlfluff lint models/
```
