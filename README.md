# DBT com Big Query

## Ricardo Marques

## üîß Configura√ß√£o do dbt com BigQuery

Este projeto utiliza o **dbt** com o **Google BigQuery** como data warehouse.

### üìå Conex√£o via Conta de Servi√ßo com Vari√°veis de Ambiente

A conex√£o com o BigQuery foi configurada utilizando uma **conta de servi√ßo**, com os dados sens√≠veis e de configura√ß√£o extra√≠dos por meio de **vari√°veis de ambiente**, garantindo maior seguran√ßa e flexibilidade.

O arquivo `profiles.yml` utiliza as vari√°veis da seguinte forma:

```yaml
datawarehouse:
  outputs:
    dev:
      type: bigquery
      method: "{{ env_var('DBT_METHOD') }}"
      project: "{{ env_var('DBT_PROJECT') }}"
      dataset: "{{ env_var('DBT_DATASET') }}"
      keyfile: "{{ env_var('DBT_KEYFILE') }}"
      threads: "{{ env_var('DBT_THREADS') | int }}"
      job_execution_timeout_seconds: "{{ env_var('DBT_JOB_TIMEOUT') | int }}"
      location: "{{ env_var('DBT_LOCATION') }}"
      priority: "{{ env_var('DBT_PRIORITY') }}"
      job_retries: "{{ env_var('DBT_JOB_RETRIES') | int }}"
  target: dev
```

üìå Definindo as Vari√°veis de Ambiente
Essas vari√°veis devem ser definidas em um arquivo .env ou exportadas no ambiente de execu√ß√£o, por exemplo:

```bash

export DBT_METHOD=service-account
export DBT_PROJECT=seu-projeto
export DBT_DATASET=seu_dataset
export DBT_KEYFILE=/caminho/para/sua-chave.json
export DBT_THREADS=1
export DBT_JOB_TIMEOUT=300
export DBT_LOCATION=US
export DBT_PRIORITY=interactive
export DBT_JOB_RETRIES=1
```
üìÅ Uso de Profile Customizado
O dbt foi configurado para utilizar um profiles.yml fora do diret√≥rio padr√£o, sendo o caminho especificado com a flag --profiles-dir:

```bash

dbt run --profiles-dir ../

```
## üîß Uso do dbt Seed para Criar Tabelas no BigQuery

No projeto, foi utilizado o comando **`dbt seed`** para criar tabelas no **BigQuery** a partir de arquivos CSV armazenados localmente. O **dbt seed** permite carregar dados diretamente para o BigQuery e √© √∫til para importar dados de refer√™ncia ou dados est√°ticos necess√°rios para os modelos.


<p align="center">
  <img src="pic/dbt-seed.png" alt="Fluxo do dbt seed para BigQuery" width="500">
</p>


### üìå Configura√ß√£o do dbt Seed

1. **Arquivos CSV**: Os arquivos CSV com os dados a serem carregados foram armazenados na pasta `seeds/` do projeto. Esses arquivos devem estar formatados corretamente para que o dbt consiga carreg√°-los no BigQuery.

2. **Comando dbt seed**: O comando `dbt seed` foi utilizado para carregar os arquivos para o BigQuery. O dbt automaticamente cria as tabelas e carrega os dados a partir dos arquivos CSV.

   O comando utilizado foi:

   ```bash
   dbt seed

   ```

3. **Estrutura das Tabelas:** Durante a execu√ß√£o do dbt seed, o dbt cria tabelas no BigQuery com o mesmo nome dos arquivos CSV, mas na schema e projeto configurados no profiles.yml.

4. **Configura√ß√£o Adicional:** Caso haja necessidade de ajustes como a defini√ß√£o de tipos de dados ou configura√ß√µes espec√≠ficas de parti√ß√£o e clustering no BigQuery, esses par√¢metros podem ser configurados diretamente no arquivo dbt_project.yml ou dentro do pr√≥prio arquivo profiles.yml.



### üèóÔ∏è Estrutura do Projeto dbt

O projeto foi estruturado seguindo as melhores pr√°ticas de modelagem com **dbt**, utilizando os diret√≥rios:

- **`staging/`**: onde s√£o feitas as primeiras transforma√ß√µes e limpezas dos dados brutos vindos do BigQuery.
- **`intermediate/`**: camada intermedi√°ria onde os dados s√£o integrados, enriquecidos e organizados para an√°lises mais complexas.
- **`marts/`**: camada final orientada ao neg√≥cio, com tabelas e m√©tricas preparadas para consumo anal√≠tico por ferramentas de BI ou dashboards.

Essa estrutura permite organizar as transforma√ß√µes de forma clara e escal√°vel, separando responsabilidades e facilitando a manuten√ß√£o.
A modelagem conduz os dados at√© o **mart anal√≠tico**, ponto final de entrega para **an√°lises de neg√≥cio**.
